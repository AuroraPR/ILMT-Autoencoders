{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fc2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from PIL import Image \n",
    "\n",
    "from pandas import read_csv  \n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.txt')\n",
    "\n",
    "source_folder = config.get('Configuration', 'source_folder')\n",
    "time_step = int(config.get('Configuration', 'time_step'))\n",
    "data_folder = config.get('Configuration', 'data_folder')\n",
    "ini_date = config.get('Configuration', 'ini_date')\n",
    "end_date = config.get('Configuration', 'end_date')\n",
    "\n",
    "window_size = int(config.get('Configuration', 'window_size'))\n",
    "\n",
    "scenes=config.get('Configuration', 'scenes')\n",
    "scenes = [(item.strip()) for item in scenes.split(',')]\n",
    "\n",
    "users=config.get('Configuration', 'users')\n",
    "users = [(item.strip()) for item in users.split(',')]\n",
    "\n",
    "other_users=config.get('Configuration', 'other_users')\n",
    "other_users = [(item.strip()) for item in other_users.split(',')]\n",
    "\n",
    "anchors=config.get('Configuration', 'anchors')\n",
    "anchors = [(item.strip()) for item in anchors.split(',')]\n",
    "\n",
    "other_anchors=config.get('Configuration', 'other_anchors')\n",
    "other_anchors = [(item.strip()) for item in other_anchors.split(',')]\n",
    "\n",
    "anchors.extend(other_anchors)\n",
    "\n",
    "room=config.get('Configuration', 'room')\n",
    "\n",
    "w = int(config.get(room, 'w'))\n",
    "h = int(config.get(room, 'h'))\n",
    "\n",
    "user_color={}\n",
    "for user in users:\n",
    "    user_color[user]=config.get('Colors', user)\n",
    "print(user_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98850536",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv    \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "off_zone=60*60*2\n",
    "\n",
    "def day_time(ti):\n",
    "    return int((int)((ti+off_zone)/(60*60*24)))\n",
    "\n",
    "\n",
    "def time2str(tt):\n",
    "    return datetime.fromtimestamp(tt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "t0 = (int)(datetime.strptime(ini_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "print (ini_date,\"Init date is\", t0, \"day:\",day_time(t0), time2str(t0))\n",
    "\n",
    "tN = (int)(datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "print (end_date,\"End date is\", tN, \"day:\",day_time(tN), time2str(tN))\n",
    "\n",
    "\n",
    "def day_time0(ti):\n",
    "    return day_time(ti)-day_time(t0)+1\n",
    "\n",
    "def relT(ti):\n",
    "    return (int)((ti-t0)/time_step)\n",
    "\n",
    "days=list(range(day_time(t0),day_time(tN)+1))\n",
    "print(days)\n",
    "\n",
    "i0=0\n",
    "ts=list(range(t0,tN,1))\n",
    "print(i0,ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94903a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_user = {}\n",
    "for d in days:\n",
    "    for user in users:\n",
    "        scene_user[user] = {}\n",
    "        for s in scenes:\n",
    "            print(d,source_folder+\"/\"+s+\"/location_gt_\"+user+\"/\"+str(d)+\".location.tsv\")\n",
    "            try:\n",
    "                series=read_csv(source_folder+\"/\"+s+\"/location_gt_\"+user+\"/\"+str(d)+\".location.tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"date\",\"time2\",\"x\",\"y\"])\n",
    "                print(d,series.size,(series[\"time\"].iloc[0],series[\"time\"].iloc[-1]))\n",
    "                scene_user[user][s] = (series[\"time\"].iloc[0],series[\"time\"].iloc[-1])\n",
    "                print(scene_user[user][s])\n",
    "            except Exception as e:\n",
    "                print(\"Not data\",e)\n",
    "                continue\n",
    "def getScene(t0):\n",
    "    for user, user_scene in scene_user.items():\n",
    "        for scene, times in user_scene.items():\n",
    "            #print(t0,times[0],times[1])\n",
    "            if(t0>times[0]-window_size/2 and t0<times[1]+window_size/2):\n",
    "                return scene\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFPImg(tt):\n",
    "    return np.array(Image.open(data_folder+\"/\"+room+\"/DAY_\"+str(day)+\"/FP.\"+str(tt)+\".png\"))/255.0\n",
    "\n",
    "def getGTImg(tt,user):\n",
    "    return np.array(Image.open(data_folder+\"/\"+room+\"/DAY_\"+str(day)+\"/GT.\"+user+\".\"+str(tt)+\".png\"))/255.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc969f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XY0={}\n",
    "rssi0={}\n",
    "Y1={}\n",
    "Y0={}\n",
    "\n",
    "T0=[]\n",
    "T1=[]\n",
    "\n",
    "for day in days:\n",
    "    anchors_data={}\n",
    "    for user in users:\n",
    "        XY0[user]=[]\n",
    "        rssi0[user]=[]\n",
    "        Y1[user]=[]\n",
    "        Y0[user]=[]\n",
    "\n",
    "\n",
    "        anchors_data[user]={}\n",
    "        for anchor in anchors:\n",
    "            print(data_folder+\"/\"+room+\"/DAY_\"+str(day)+\"/\"+user+\".\"+anchor+\".tsv\")\n",
    "            print(user,anchor)\n",
    "            series=read_csv(data_folder+\"/\"+room+\"/DAY_\"+str(day)+\"/\"+user+\".\"+anchor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"d\"])\n",
    "            series=series.values\n",
    "            anchors_data[user][anchor]=series\n",
    "            \n",
    "\n",
    "    for it,tt in enumerate(ts):\n",
    "        imgX=getFPImg(tt)\n",
    "        print(\"imgX\",imgX.shape)\n",
    "\n",
    "        for user in users:\n",
    "            \n",
    "            imgY=getGTImg(tt,user)\n",
    "            print(\"user\",user,\"imgY\",imgY.shape)\n",
    "\n",
    "            dist=[]\n",
    "            for ixa,anchor in enumerate(anchors):\n",
    "                d=anchors_data[user][anchor][it][1]\n",
    "                if(d>0):\n",
    "                    d=d/10.0\n",
    "                if(d>1):\n",
    "                    d=1\n",
    "                print(\"\\t anchor:\",anchor, anchors_data[user][anchor][it], \"tt:\",tt)\n",
    "                dist.append(d)\n",
    "\n",
    "            dist=np.array(dist)\n",
    "            print(\"dist:\",dist)\n",
    "\n",
    "            rssi0[user].append(dist.reshape(len(anchors),1))\n",
    "            XY0[user].append(imgX[:, :, np.newaxis])\n",
    "            T0.append(it)\n",
    "            T1.append(tt)\n",
    "            Y1[user].append(\"1\")\n",
    "            Y0[user].append(imgY[:, :, np.newaxis])\n",
    "        \n",
    "T0=list(dict.fromkeys(T0))\n",
    "T1=list(dict.fromkeys(T1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a451e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in days:\n",
    "    anchors_data={}\n",
    "    for user in other_users:\n",
    "        XY0[user]=[]\n",
    "        rssi0[user]=[]\n",
    "        Y1[user]=[]\n",
    "        Y0[user]=[]\n",
    "\n",
    "        anchors_data[user]={}\n",
    "        for anchor in anchors:\n",
    "            print(data_folder+\"/\"+room+\"/DAY_\"+str(day)+\"/\"+user+\".\"+anchor+\".tsv\")\n",
    "            print(user,anchor)\n",
    "            series=read_csv(data_folder+\"/\"+room+\"/DAY_\"+str(day)+\"/\"+user+\".\"+anchor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"d\"])\n",
    "            series=series.values\n",
    "            anchors_data[user][anchor]=series\n",
    "            \n",
    "    for it,tt in enumerate(ts):\n",
    "        imgX=getFPImg(tt)\n",
    "        print(\"imgX\",imgX.shape)\n",
    "\n",
    "        for user in other_users:\n",
    "            \n",
    "            #imgY=getGTImg(tt,user)\n",
    "            #print(\"user\",user,\"imgY\",imgY.shape)\n",
    "            \n",
    "            dist=[]\n",
    "            for ixa,anchor in enumerate(anchors):\n",
    "                d=anchors_data[user][anchor][it][1]\n",
    "                if(d>0):\n",
    "                    d=d/10.0\n",
    "                if(d>1):\n",
    "                    d=1\n",
    "                print(\"\\t anchor:\",anchor, anchors_data[user][anchor][it], \"tt:\",tt)\n",
    "                dist.append(d)\n",
    "\n",
    "            dist=np.array(dist)\n",
    "            print(\"dist:\",dist)\n",
    "\n",
    "            rssi0[user].append(dist.reshape(len(anchors),1))\n",
    "            XY0[user].append(imgX[:, :, np.newaxis])\n",
    "            T0.append(it)\n",
    "            T1.append(tt)\n",
    "            Y1[user].append(\"0\")      \n",
    "            #Y0[user].append(imgY[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aead90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    XY0[user]=np.array(XY0[user])\n",
    "    rssi0[user]=np.array(rssi0[user])\n",
    "    Y0[user]=np.array(Y0[user])\n",
    "for user in other_users:\n",
    "    XY0[user]=np.array(XY0[user])\n",
    "    rssi0[user]=np.array(rssi0[user])\n",
    "\n",
    "T0=np.array(T0)\n",
    "T1=np.array(T1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(rssi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8774df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "minT=np.min(T0)\n",
    "maxT=np.max(T0)\n",
    "\n",
    "#print(XY0.shape)\n",
    "#print(rssi0.shape)\n",
    "\n",
    "print(minT)\n",
    "print(maxT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e149df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "XYT=[]\n",
    "rssiT=[]\n",
    "YT=[]\n",
    "\n",
    "TA=int(window_size/2)\n",
    "TB=int(window_size/2)\n",
    "\n",
    "#T1Y=3\n",
    "#T2Y=3\n",
    "\n",
    "T=window_size\n",
    "\n",
    "S=[]\n",
    "\n",
    "for user in users:\n",
    "    for t in range(minT+TA,maxT-TB):\n",
    "\n",
    "        \n",
    "        tt=T1[t]\n",
    "        scene=getScene(tt)\n",
    "        print(\"Scene\",scene,tt,t)\n",
    "        if not scene:\n",
    "            continue\n",
    "                    \n",
    "        label=Y1[user][t]\n",
    "\n",
    "        subW=list(range(t-TA,t+TB))\n",
    "        print(\"subW:\",subW, \"t:\",t)\n",
    "        if not (set(subW).intersection(set(T0)) == set(subW)):\n",
    "            print(\"Not data for sliding window!\",t)\n",
    "            continue\n",
    "\n",
    "        print(\"rssi0[t-T:t+T]\",rssi0[user])\n",
    "        if(all(map(lambda x: x == -1, rssi0[user][t-TA:t+TB].flatten()))):\n",
    "            print(\"Distance -1 for RSSI in sliding window!\",t)\n",
    "            continue\n",
    "\n",
    "        #if(all(map(lambda x: x == -1, rssi0[t:t+T2].flatten()))):\n",
    "        #    print(\"Distance -1 for RSSI in sliding window!\",t)\n",
    "        #    continue\n",
    "\n",
    "        if(all(map(lambda x: x == 0, Y0[user][t-TA:t+TB].flatten()))):\n",
    "            print(\"Distance 0 for Y0 in t!\",time2str(tt))\n",
    "            #label=\"0\"     \n",
    "\n",
    "        if(XY0[user][t-TA:t+TB].shape[0]!=T):\n",
    "            print(\"#\",XY0[user][t-TA:t+TB].shape)\n",
    "            continue\n",
    "        if(rssi0[user][t-TA:t+TB].shape[0]!=T):\n",
    "            print(\"@\",rssi0[user][t-TA:t+TB].shape)\n",
    "            continue\n",
    "\n",
    "        XYT.append(XY0[user][t-TA:t+TB])\n",
    "        rssiT.append(rssi0[user][t-TA:t+TB])\n",
    "        YT.append(label)\n",
    "        S.append(scene)\n",
    "        \n",
    "for user in other_users:\n",
    "    for t in range(minT+TA,maxT-TB):\n",
    "        tt=T1[t]\n",
    "        scene=getScene(tt)\n",
    "        print(\"Scene\",scene,tt,t)\n",
    "        if not scene:\n",
    "            continue\n",
    "            \n",
    "        label=Y1[user][t]\n",
    "\n",
    "        subW=list(range(t-TA,t+TB))\n",
    "        print(\"subW:\",subW, \"t:\",t)\n",
    "        if not (set(subW).intersection(set(T0)) == set(subW)):\n",
    "            print(\"Not data for sliding window!\",t)\n",
    "            continue\n",
    "\n",
    "        print(\"rssi0[t-T:t+T]\",rssi0[user][t-TA:t+TB].flatten())\n",
    "        if(all(map(lambda x: x == -1, rssi0[user][t-TA:t+TB].flatten()))):\n",
    "            print(\"Distance -1 for RSSI in sliding window!\",t)\n",
    "            continue\n",
    "\n",
    "        #if(all(map(lambda x: x == -1, rssi0[t:t+T2].flatten()))):\n",
    "        #    print(\"Distance -1 for RSSI in sliding window!\",t)\n",
    "        #    continue\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "        if(XY0[user][t-TA:t+TB].shape[0]!=T):\n",
    "            print(\"#\",XY0[user][t-TA:t+TB].shape)\n",
    "            continue\n",
    "        if(rssi0[user][t-TA:t+TB].shape[0]!=T):\n",
    "            print(\"@\",rssi0[user][t-TA:t+TB].shape)\n",
    "            continue\n",
    "\n",
    "        XYT.append(XY0[user][t-TA:t+TB])\n",
    "        rssiT.append(rssi0[user][t-TA:t+TB])\n",
    "        YT.append(label)\n",
    "        S.append(scene)        \n",
    "\n",
    "XYT=np.array(XYT)\n",
    "rssiT=np.array(rssiT)\n",
    "YT=np.array(YT)    \n",
    "S=np.array(S)    \n",
    "\n",
    "print(XYT.shape)\n",
    "print(rssiT.shape)\n",
    "print(YT.shape)\n",
    "print(S.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101eb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(YT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPooling2D,Activation, Dense\n",
    "\n",
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Softmax,Input, Conv1D, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense,Dropout,LSTM,TimeDistributed,MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPooling2D,Activation, Dense\n",
    "\n",
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Lambda, Dot,Reshape,Multiply, Input, Conv1D, Conv2D, ConvLSTM2D,ReLU,UpSampling2D, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense,Dropout,LSTM,TimeDistributed,MaxPooling1D, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from keras import backend as K\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=len(anchors)\n",
    "print(K)\n",
    "print(T)\n",
    "rssi = Input(shape=(T,K,1))\n",
    "print(rssi)\n",
    "\n",
    "encoded_rssi = TimeDistributed(Conv1D(32, 3, activation='relu', padding='same',\n",
    "        input_shape=(T, K, 1)))(rssi)\n",
    "#encoded_rssi = TimeDistributed(MaxPooling1D(2, padding='same'))(encoded_rssi)\n",
    "encoded_rssi = TimeDistributed(Conv1D(64, 3, activation='relu', padding='same'))(encoded_rssi)\n",
    "print(encoded_rssi)\n",
    "encoded_rssi = TimeDistributed(Dropout(0.25))(encoded_rssi)\n",
    "encoded_rssi = TimeDistributed(Flatten())(encoded_rssi)\n",
    "\n",
    "encoded_rssi=LSTM(128, return_sequences=True)(encoded_rssi)\n",
    "encoded_rssi = Dropout(0.25)(encoded_rssi)\n",
    "encoded_rssi=LSTM(128, return_sequences=True)(encoded_rssi)\n",
    "print(\"lstm\",encoded_rssi)\n",
    "encoded_rssi=Reshape((T,1,1,128))(encoded_rssi)\n",
    "\n",
    "print(\"lstm\",encoded_rssi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=w\n",
    "M=h\n",
    "\n",
    "xy = Input(shape=(T,N,M,1))\n",
    "print(xy)\n",
    "\n",
    "encoded = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        input_shape=(T, N, M, 1))(xy)\n",
    "encoded = TimeDistributed(MaxPooling2D((2, 2), padding='same'))(encoded)\n",
    "encoded = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(encoded)\n",
    "encoded = TimeDistributed(Dropout(0.25))(encoded)\n",
    "#encoded = TimeDistributed(MaxPooling2D((2, 2), padding='same'))(encoded)\n",
    "#encoded = TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same'))(encoded)\n",
    "#encoded = TimeDistributed(MaxPooling2D((2, 2), padding='same'))(encoded)\n",
    "#encoded = TimeDistributed(Conv2D(256, (3, 3), activation='relu', padding='same'))(encoded)\n",
    "print(encoded)\n",
    "\n",
    "#LayerNormalization\n",
    "encoded= ConvLSTM2D(128 , 3,return_sequences=True, padding='same')(encoded)\n",
    "encoded = Dropout(0.25)(encoded)\n",
    "encoded= ConvLSTM2D(128 , 3,return_sequences=True, padding='same')(encoded)\n",
    "\n",
    "\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffed59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#merged=Multiply()([encoded, encoded_rssi])\n",
    "encoded_rssi2=Reshape((4,128))(encoded_rssi)\n",
    "print(encoded_rssi2)\n",
    "print(encoded)\n",
    "merged=Dot(axes=[4, 2])([encoded, encoded_rssi2])\n",
    "merged=Softmax()(merged)\n",
    "# Create a lambda layer to expand dimensions of input2\n",
    "#expand_dim = Lambda(lambda x: tf.repeat(x, 8, axis=3))(encoded_rssi)  # Repeat along axis 2\n",
    "#merged=Concatenate(axis=2)([encoded, encoded_rssi])\n",
    "\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense=  Flatten()(merged)\n",
    "dense = Dropout(0.25)(dense)\n",
    "dense = Dense(1024)(dense)\n",
    "dense = Dropout(0.25)(dense)\n",
    "dense = Dense(512)(dense)\n",
    "dense = Dense(2, activation=\"softmax\")(dense)\n",
    "\n",
    "# Compile model\n",
    "autoencoder = Model([xy,rssi], dense)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#autoencoder.compile(optimizer=Adam(learning_rate=0.001),\n",
    "#              loss=CategoricalCrossentropy(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "print(encoded)\n",
    "autoencoder.summary()\n",
    "autoencoder.save(\"autoencoder.room.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e65f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Use LabelEncoder to convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "numerical_labels = label_encoder.fit_transform(YT)\n",
    "\n",
    "YT_categorical=to_categorical(YT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "\n",
    "Y_pred_total=np.array([])\n",
    "\n",
    "print(np.unique(S))\n",
    "\n",
    "total_execution_time = 0\n",
    "\n",
    "print(label_encoder.classes_)\n",
    "def create_class_weight(labels_dict,label_encoder,mu=0.15):\n",
    "    total = np.sum(list(labels_dict.values()))\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "    \n",
    "    for key in keys:\n",
    "        score = math.log(mu*total/float(labels_dict[key]))\n",
    "        class_weight[label_encoder.transform([key])[0]] = score if score > 1.0 else 1.0\n",
    "    \n",
    "    return class_weight\n",
    "\n",
    "for ixs,sc in enumerate(np.unique(S)):\n",
    "    \n",
    "    #obtenemos train and test index basado en la escena ( y luego lo barajamos)\n",
    "    train_indices=np.where(S != sc)[0]\n",
    "    test_indices=np.where(S == sc)[0]\n",
    "    \n",
    "    np.random.shuffle(train_indices)\n",
    "\n",
    "    #datos de train y test\n",
    "    print(\"SCENE\", sc, \" TRAIN:\", train_indices, \" TEST:\", test_indices)\n",
    "    \n",
    "    XYT_train=XYT[train_indices].copy()\n",
    "    rssiT_train=rssiT[train_indices].copy()\n",
    "    YT_train=YT_categorical[train_indices].copy()\n",
    "    YT_train0=YT[train_indices].copy()\n",
    "\n",
    "    XYT_test=XYT[test_indices].copy()\n",
    "    rssiT_test=rssiT[test_indices].copy()\n",
    "    YT_test=YT_categorical[test_indices].copy()\n",
    "    \n",
    "    autoencoder = load_model(\"autoencoder.room.h5\")\n",
    "    class_labels = np.unique(YT_train0)\n",
    "    print(class_labels)\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                         classes=np.unique(YT_train0),\n",
    "                                         y=YT_train0)\n",
    "    \n",
    "    print(class_weights)\n",
    "    # Create a dictionary with class labels as keys and corresponding weights as values\n",
    "    class_weight_dict = {label_encoder.transform([class_label])[0]: weight for class_label, weight in zip(class_labels, class_weights)}\n",
    "\n",
    "    # Print the dictionary\n",
    "    print(class_weight_dict)\n",
    "\n",
    "    print(\"Counter(YT_train)\",Counter(YT_train0))\n",
    "    #class_weight_dict =create_class_weight(Counter(YT_train0),YT_train0)\n",
    "    #print(class_weight_dict)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = autoencoder.fit([XYT_train,rssiT_train] , YT_train, batch_size=16, class_weight=class_weight_dict,validation_data=([XYT_test,rssiT_test] , YT_test),epochs=25)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    y_pred = autoencoder.predict([XYT_test,rssiT_test]).argmax(axis=1)\n",
    "    y_val=YT_test.argmax(axis=1)\n",
    "    print(y_pred)\n",
    "    print(y_val)\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred) \n",
    "    print(cm)\n",
    "    print(\"training time:\",training_time)\n",
    "    print(classification_report(y_val, y_pred, target_names=[\"out\",\"in\"]))\n",
    "\n",
    "\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"out\",\"in\"])\n",
    "\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    \n",
    "    Y_pred_total=np.concatenate((Y_pred_total,y_pred))\n",
    "    \n",
    "    total_execution_time = total_execution_time+training_time\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Total training time:\",total_execution_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
